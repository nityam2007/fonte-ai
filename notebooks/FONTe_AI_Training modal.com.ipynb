{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0aa2c47",
   "metadata": {},
   "source": [
    "# üé® FONTe AI - B200 Training (Modal.com)\n",
    "\n",
    "**Run this notebook directly on Modal.com**\n",
    "\n",
    "GPU: B200 (192GB) @ $6.25/hr | ~50 epochs in ~1.3 hours | ~$8 total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d374cfd",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43857891",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install git-lfs -qq\n",
    "!git lfs install\n",
    "!git clone https://github.com/nityam2007/fonte-ai.git\n",
    "%cd fonte-ai\n",
    "!git lfs pull\n",
    "!nvidia-smi --query-gpu=name,memory.total --format=csv\n",
    "!ls -lh TOKENIZED/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eb2b06",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, json, struct, time, os\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Config\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 50\n",
    "LR = 3e-4\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    vocab_size: int = 1105\n",
    "    max_seq_length: int = 512\n",
    "    d_model: int = 256\n",
    "    n_heads: int = 4\n",
    "    n_layers: int = 6\n",
    "    d_ff: int = 1024\n",
    "    dropout: float = 0.1\n",
    "    pad_token_id: int = 0\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(max_len).unsqueeze(1).float()\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    def forward(self, x):\n",
    "        return self.dropout(x + self.pe[:, :x.size(1)])\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_heads, self.d_k = n_heads, d_model // n_heads\n",
    "        self.wq = nn.Linear(d_model, d_model)\n",
    "        self.wk = nn.Linear(d_model, d_model)\n",
    "        self.wv = nn.Linear(d_model, d_model)\n",
    "        self.wo = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x, mask=None):\n",
    "        B, L, D = x.shape\n",
    "        q = self.wq(x).view(B, L, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        k = self.wk(x).view(B, L, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        v = self.wv(x).view(B, L, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        scores = (q @ k.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        attn = self.dropout(F.softmax(scores, dim=-1))\n",
    "        out = (attn @ v).transpose(1, 2).reshape(B, L, -1)\n",
    "        return self.wo(out)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model, d_ff), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_ff, d_model))\n",
    "        self.n1 = nn.LayerNorm(d_model)\n",
    "        self.n2 = nn.LayerNorm(d_model)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    def forward(self, x, mask=None):\n",
    "        x = x + self.drop(self.attn(self.n1(x), mask))\n",
    "        return x + self.drop(self.ff(self.n2(x)))\n",
    "\n",
    "class FonteModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.emb = nn.Embedding(cfg.vocab_size, cfg.d_model, padding_idx=cfg.pad_token_id)\n",
    "        self.pos = PositionalEncoding(cfg.d_model, cfg.max_seq_length, cfg.dropout)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(cfg.d_model, cfg.n_heads, cfg.d_ff, cfg.dropout) for _ in range(cfg.n_layers)])\n",
    "        self.norm = nn.LayerNorm(cfg.d_model)\n",
    "        self.head = nn.Linear(cfg.d_model, cfg.vocab_size, bias=False)\n",
    "        self.head.weight = self.emb.weight\n",
    "        self.register_buffer('mask', torch.tril(torch.ones(cfg.max_seq_length, cfg.max_seq_length)))\n",
    "    def forward(self, x, labels=None):\n",
    "        x = self.pos(self.emb(x))\n",
    "        m = self.mask[:x.size(1), :x.size(1)]\n",
    "        for b in self.blocks:\n",
    "            x = b(x, m)\n",
    "        logits = self.head(self.norm(x))\n",
    "        if labels is not None:\n",
    "            loss = F.cross_entropy(logits[:, :-1].reshape(-1, self.cfg.vocab_size), labels[:, 1:].reshape(-1), ignore_index=self.cfg.pad_token_id)\n",
    "            return {'logits': logits, 'loss': loss}\n",
    "        return {'logits': logits}\n",
    "\n",
    "class FonteDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            n, ml, _ = struct.unpack('III', f.read(12))\n",
    "            self.data = []\n",
    "            for _ in range(n):\n",
    "                f.read(2)  # skip length\n",
    "                self.data.append(list(struct.unpack(f'{ml}H', f.read(ml * 2))))\n",
    "        print(f\"  Loaded {len(self.data)} sequences from {path}\")\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        return {'input_ids': torch.tensor(self.data[i], dtype=torch.long)}\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "train_ds = FonteDataset('TOKENIZED/train.bin')\n",
    "val_ds = FonteDataset('TOKENIZED/val.bin')\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, num_workers=0)\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Batches/epoch: {len(train_dl)}\")\n",
    "\n",
    "# Model\n",
    "model = FonteModel(ModelConfig()).to(DEVICE)\n",
    "opt = AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "sched = CosineAnnealingLR(opt, T_max=len(train_dl) * EPOCHS)\n",
    "print(f\"Model: {sum(p.numel() for p in model.parameters() if p.requires_grad):,} params on {DEVICE}\")\n",
    "\n",
    "# Training\n",
    "os.makedirs('TRAINED', exist_ok=True)\n",
    "history, best_loss = [], float('inf')\n",
    "\n",
    "print(f\"\\nüöÄ Training {EPOCHS} epochs...\")\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_dl, desc=f\"Epoch {epoch}/{EPOCHS}\"):\n",
    "        x = batch['input_ids'].to(DEVICE)\n",
    "        loss = model(x, x)['loss']\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        sched.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_dl)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = sum(model(b['input_ids'].to(DEVICE), b['input_ids'].to(DEVICE))['loss'].item() for b in val_dl) / len(val_dl)\n",
    "    \n",
    "    print(f\"Epoch {epoch} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\")\n",
    "    history.append({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss})\n",
    "    \n",
    "    # Save checkpoint every epoch\n",
    "    torch.save({'config': model.cfg.__dict__, 'state_dict': model.state_dict(), 'epoch': epoch,\n",
    "                'train_loss': train_loss, 'val_loss': val_loss}, f'TRAINED/checkpoint_epoch_{epoch}.pt')\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save({'config': model.cfg.__dict__, 'state_dict': model.state_dict()}, 'TRAINED/best_model.pt')\n",
    "        print(f\"  üíæ Best model saved!\")\n",
    "    \n",
    "    with open('TRAINED/training_history.json', 'w') as f:\n",
    "        json.dump(history, f)\n",
    "\n",
    "print(f\"\\n‚úÖ Done! Best val_loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a37051",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Download Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93625ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all checkpoints\n",
    "!ls -lh TRAINED/\n",
    "\n",
    "# If on Modal, download via modal volume or use:\n",
    "# !zip -r trained_models.zip TRAINED/\n",
    "# Then download trained_models.zip from Modal UI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
