{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0aa2c47",
   "metadata": {},
   "source": [
    "# \ud83c\udfa8 FONTe AI - Font Generation Training\n",
    "\n",
    "**AI-powered unique font generation using SVG Path Transformers**\n",
    "\n",
    "Repository: [github.com/nityam2007/fonte-ai](https://github.com/nityam2007/fonte-ai)\n",
    "\n",
    "---\n",
    "\n",
    "## What this notebook does:\n",
    "1. \u2705 Clone repository with training data (Git LFS)\n",
    "2. \u2705 Setup environment\n",
    "3. \u2705 Load pre-tokenized dataset (248K sequences)\n",
    "4. \u2705 **Auto-resume from checkpoint** (for 4-hour limit!)\n",
    "5. \u2705 Train SVG Path Transformer model\n",
    "6. \u2705 Generate sample fonts\n",
    "7. \u2705 Save model to Drive\n",
    "\n",
    "**Requirements:** Google Colab (Free T4 GPU works!)\n",
    "\n",
    "---\n",
    "\n",
    "### \u26a1 4-Hour Session Strategy:\n",
    "- **Batch size 128** \u2192 ~14 min/epoch (faster!)\n",
    "- **Saves every epoch** \u2192 Never lose progress\n",
    "- **Auto-resume** \u2192 Just run notebook again to continue\n",
    "- **~15 epochs/session** \u2192 4 sessions for 50 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d374cfd",
   "metadata": {},
   "source": [
    "---\n",
    "## 1\ufe0f\u20e3 Setup & Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43857891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi --query-gpu=name,memory.total --format=csv\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3670d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (for saving checkpoints)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project folder in Drive\n",
    "!mkdir -p /content/drive/MyDrive/fonte_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a25a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Git LFS and clone repository\n",
    "!apt-get install git-lfs -qq\n",
    "!git lfs install\n",
    "\n",
    "# Clone the repository (includes LFS files)\n",
    "%cd /content\n",
    "!git clone https://github.com/nityam2007/fonte-ai.git\n",
    "%cd fonte-ai\n",
    "\n",
    "# Pull LFS files\n",
    "!git lfs pull\n",
    "\n",
    "# Check data files\n",
    "!ls -lh TOKENIZED/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eb2b06",
   "metadata": {},
   "source": [
    "---\n",
    "## 2\ufe0f\u20e3 Model Architecture\n",
    "\n",
    "SVG Path Transformer - treats font glyphs as sequences of path commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import struct\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    vocab_size: int = 1106\n",
    "    max_seq_length: int = 512\n",
    "    d_model: int = 256\n",
    "    n_heads: int = 4\n",
    "    n_layers: int = 6\n",
    "    d_ff: int = 1024\n",
    "    dropout: float = 0.1\n",
    "    pad_token_id: int = 0\n",
    "    sos_token_id: int = 1\n",
    "    eos_token_id: int = 2\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 512, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        q = self.w_q(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        k = self.w_k(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        v = self.w_v(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = out.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "        return self.w_o(out)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(F.gelu(self.linear1(x))))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int, d_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = x + self.dropout(self.attention(self.norm1(x), mask))\n",
    "        x = x + self.dropout(self.ff(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class FonteModel(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.token_embedding = nn.Embedding(config.vocab_size, config.d_model, padding_idx=config.pad_token_id)\n",
    "        self.pos_encoding = PositionalEncoding(config.d_model, config.max_seq_length, config.dropout)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(config.d_model, config.n_heads, config.d_ff, config.dropout)\n",
    "            for _ in range(config.n_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(config.d_model)\n",
    "        self.lm_head = nn.Linear(config.d_model, config.vocab_size, bias=False)\n",
    "        self.lm_head.weight = self.token_embedding.weight\n",
    "        self.apply(self._init_weights)\n",
    "        self.register_buffer('causal_mask', torch.tril(torch.ones(config.max_seq_length, config.max_seq_length)))\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        x = self.token_embedding(input_ids)\n",
    "        x = self.pos_encoding(x)\n",
    "        mask = self.causal_mask[:seq_len, :seq_len]\n",
    "        for block in self.blocks:\n",
    "            x = block(x, mask)\n",
    "        x = self.norm(x)\n",
    "        logits = self.lm_head(x)\n",
    "        result = {'logits': logits}\n",
    "        if labels is not None:\n",
    "            shift_logits = logits[:, :-1, :].contiguous()\n",
    "            shift_labels = labels[:, 1:].contiguous()\n",
    "            loss = F.cross_entropy(shift_logits.view(-1, self.config.vocab_size), shift_labels.view(-1), ignore_index=self.config.pad_token_id)\n",
    "            result['loss'] = loss\n",
    "        return result\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, style_id, char_id, max_length=256, temperature=1.0, top_k=50, top_p=0.9):\n",
    "        self.eval()\n",
    "        device = next(self.parameters()).device\n",
    "        tokens = torch.tensor([[self.config.sos_token_id, style_id, char_id]], device=device)\n",
    "        for _ in range(max_length - 3):\n",
    "            outputs = self.forward(tokens)\n",
    "            logits = outputs['logits'][:, -1, :] / temperature\n",
    "            if top_k > 0:\n",
    "                indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "                logits[indices_to_remove] = float('-inf')\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            tokens = torch.cat([tokens, next_token], dim=1)\n",
    "            if next_token.item() == self.config.eos_token_id:\n",
    "                break\n",
    "        return tokens\n",
    "\n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save({'config': self.config.__dict__, 'state_dict': self.state_dict()}, path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path, device='cpu'):\n",
    "        checkpoint = torch.load(path, map_location=device)\n",
    "        config = ModelConfig(**checkpoint['config'])\n",
    "        model = cls(config)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        return model\n",
    "\n",
    "\n",
    "print(\"\u2705 Model classes defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a37051",
   "metadata": {},
   "source": [
    "---\n",
    "## 3\ufe0f\u20e3 Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93625ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FonteDataset(Dataset):\n",
    "    def __init__(self, data_path, max_length=512):\n",
    "        self.max_length = max_length\n",
    "        with open(data_path, 'rb') as f:\n",
    "            num_sequences, max_length, vocab_size = struct.unpack('III', f.read(12))\n",
    "            self.token_ids = []\n",
    "            self.lengths = []\n",
    "            for _ in range(num_sequences):\n",
    "                length = struct.unpack('H', f.read(2))[0]\n",
    "                tokens = list(struct.unpack(f'{max_length}H', f.read(max_length * 2)))\n",
    "                self.lengths.append(length)\n",
    "                self.token_ids.append(tokens)\n",
    "        print(f\"Loaded {len(self.token_ids)} sequences\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.token_ids[idx], dtype=torch.long),\n",
    "            'length': self.lengths[idx],\n",
    "        }\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = FonteDataset('TOKENIZED/train.bin')\n",
    "val_dataset = FonteDataset('TOKENIZED/val.bin')\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873d295b",
   "metadata": {},
   "source": [
    "---\n",
    "## 4\ufe0f\u20e3 Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25740497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# TRAINING CONFIG - Optimized for 4-hour Colab sessions\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "BATCH_SIZE = 128         # \u26a1 Increased for faster epochs (~14 min instead of 28)\n",
    "EPOCHS = 50              # Total epochs (will resume from checkpoint)\n",
    "LEARNING_RATE = 3e-4\n",
    "SAVE_EVERY = 1           # Save EVERY epoch for session continuity\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Model config (medium size ~12M params)\n",
    "config = ModelConfig(\n",
    "    vocab_size=1106,\n",
    "    max_seq_length=512,\n",
    "    d_model=256,\n",
    "    n_heads=4,\n",
    "    n_layers=6,\n",
    "    d_ff=1024,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# RESUME FROM CHECKPOINT (if exists)\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "import glob\n",
    "import os\n",
    "\n",
    "checkpoint_dir = '/content/drive/MyDrive/fonte_ai'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoints = glob.glob(f'{checkpoint_dir}/checkpoint_epoch_*.pt')\n",
    "START_EPOCH = 1\n",
    "\n",
    "if checkpoints:\n",
    "    # Find latest checkpoint\n",
    "    latest = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    START_EPOCH = int(latest.split('_')[-1].split('.')[0]) + 1\n",
    "    \n",
    "    if START_EPOCH <= EPOCHS:\n",
    "        print(f\"\ud83d\udcc2 Found checkpoint: {latest}\")\n",
    "        model = FonteModel.load(latest, device=DEVICE).to(DEVICE)\n",
    "        print(f\"\u2705 Resuming from epoch {START_EPOCH}\")\n",
    "    else:\n",
    "        print(f\"\u2705 Training already complete! (epoch {START_EPOCH-1})\")\n",
    "        model = FonteModel(config).to(DEVICE)\n",
    "else:\n",
    "    print(\"\ud83c\udd95 Starting fresh training\")\n",
    "    model = FonteModel(config).to(DEVICE)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Model parameters: {model.count_parameters():,}\")\n",
    "print(f\"\ud83d\udda5\ufe0f Device: {DEVICE}\")\n",
    "print(f\"\ud83d\udce6 Batch size: {BATCH_SIZE}\")\n",
    "print(f\"\ud83c\udfaf Epochs: {START_EPOCH} \u2192 {EPOCHS}\")\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Optimizer & Scheduler (recreate for resumed training)\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "completed_steps = len(train_loader) * (START_EPOCH - 1)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=total_steps, last_epoch=completed_steps-1 if completed_steps > 0 else -1)\n",
    "\n",
    "# Estimate time\n",
    "est_epoch_time = len(train_loader) / 2.5 / 60  # ~2.5 it/s with batch 128\n",
    "remaining_epochs = EPOCHS - START_EPOCH + 1\n",
    "print(f\"\\n\u23f1\ufe0f Est. {est_epoch_time:.0f} min/epoch \u00d7 {remaining_epochs} epochs = {est_epoch_time * remaining_epochs:.0f} min total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e6c4b",
   "metadata": {},
   "source": [
    "---\n",
    "## 5\ufe0f\u20e3 Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in pbar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs['loss']\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        total_loss += outputs['loss'].item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# TRAINING LOOP - With checkpoint resuming\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "# Load history if resuming\n",
    "history_path = f'{checkpoint_dir}/training_history.json'\n",
    "if os.path.exists(history_path) and START_EPOCH > 1:\n",
    "    with open(history_path, 'r') as f:\n",
    "        history = json.load(f)\n",
    "    best_val_loss = min(h['val_loss'] for h in history)\n",
    "    print(f\"\ud83d\udcc8 Loaded history: {len(history)} epochs, best val_loss: {best_val_loss:.4f}\")\n",
    "else:\n",
    "    history = []\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "print(f\"\\n\ud83d\ude80 Starting training from epoch {START_EPOCH}...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS + 1):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, DEVICE)\n",
    "    val_loss = validate(model, val_loader, DEVICE)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    history.append({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss})\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | Train: {train_loss:.4f} | Val: {val_loss:.4f} | Time: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        model.save('best_model.pt')\n",
    "        model.save(f'{checkpoint_dir}/best_model.pt')\n",
    "        print(f\"  \ud83d\udcbe New best model! (val_loss: {val_loss:.4f})\")\n",
    "    \n",
    "    # Save checkpoint EVERY epoch (for 4-hour session limit)\n",
    "    model.save(f'{checkpoint_dir}/checkpoint_epoch_{epoch}.pt')\n",
    "    \n",
    "    # Save history after each epoch\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "    \n",
    "    # Time estimate\n",
    "    elapsed = time.time() - start_time\n",
    "    epochs_done = epoch - START_EPOCH + 1\n",
    "    epochs_left = EPOCHS - epoch\n",
    "    if epochs_done > 0:\n",
    "        eta = (elapsed / epochs_done) * epochs_left\n",
    "        print(f\"  \u23f1\ufe0f ETA: {eta/60:.0f} min remaining\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n\u2705 Session complete! Trained epochs {START_EPOCH}-{epoch} in {total_time/60:.1f} minutes\")\n",
    "print(f\"\ud83c\udfc6 Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"\ud83d\udcbe Checkpoints saved to: {checkpoint_dir}\")\n",
    "\n",
    "# Show how to resume\n",
    "if epoch < EPOCHS:\n",
    "    print(f\"\\n\ud83d\udccc To continue: Just run this notebook again from the start!\")\n",
    "    print(f\"   It will auto-resume from epoch {epoch + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0654e1",
   "metadata": {},
   "source": [
    "---\n",
    "## 6\ufe0f\u20e3 Test Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = FonteModel.load('best_model.pt', device=DEVICE)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Style and character token mappings\n",
    "STYLE_IDS = {\n",
    "    'serif': 28,\n",
    "    'sans-serif': 29,\n",
    "    'monospace': 30,\n",
    "    'handwriting': 31,\n",
    "    'display': 32,\n",
    "}\n",
    "\n",
    "CHAR_IDS = {char: 33 + i for i, char in enumerate(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789!@#$%&*()-+=[]\")}\n",
    "\n",
    "# Generate a sample\n",
    "style = 'serif'\n",
    "char = 'A'\n",
    "\n",
    "tokens = model.generate(\n",
    "    style_id=STYLE_IDS[style],\n",
    "    char_id=CHAR_IDS[char],\n",
    "    max_length=256,\n",
    "    temperature=0.8,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "print(f\"Generated {style} '{char}':\")\n",
    "print(f\"Tokens: {tokens[0].tolist()[:30]}...\")\n",
    "print(f\"Total tokens: {tokens.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7606e48",
   "metadata": {},
   "source": [
    "---\n",
    "## 7\ufe0f\u20e3 Save Training History & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69153232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Drive\n",
    "!mkdir -p /content/drive/MyDrive/fonte_ai\n",
    "\n",
    "model.save('/content/drive/MyDrive/fonte_ai/final_model.pt')\n",
    "print(\"\u2705 Model saved to Google Drive!\")\n",
    "\n",
    "# Save training history\n",
    "with open('/content/drive/MyDrive/fonte_ai/training_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "# Download to local\n",
    "from google.colab import files\n",
    "files.download('best_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4343bd8c",
   "metadata": {},
   "source": [
    "## \ud83c\udf89 Done!\n",
    "\n",
    "Your model is trained! Next steps:\n",
    "1. Download `best_model.pt`\n",
    "2. Use the generation script to create fonts\n",
    "3. Convert to TTF using svgtofont"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}